"use strict";(globalThis.webpackChunkphysical_ai_textbook=globalThis.webpackChunkphysical_ai_textbook||[]).push([[3766],{5739(n,e,i){i.r(e),i.d(e,{assets:()=>o,contentTitle:()=>r,default:()=>h,frontMatter:()=>a,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"module-4-vla/chapter-3-cognitive-planning","title":"Chapter 3: Cognitive Planning with LLMs - The Mind Behind the Robot","description":"Learning Objectives","source":"@site/docs/module-4-vla/chapter-3-cognitive-planning.md","sourceDirName":"module-4-vla","slug":"/module-4-vla/chapter-3-cognitive-planning","permalink":"/Hackathons/docs/module-4-vla/chapter-3-cognitive-planning","draft":false,"unlisted":false,"editUrl":"https://github.com/muslim785/Hackathons/tree/main/docs/module-4-vla/chapter-3-cognitive-planning.md","tags":[],"version":"current","frontMatter":{},"sidebar":"docs","previous":{"title":"Chapter 2: Voice-to-Action Pipelines - Speech as Robot Control Interface","permalink":"/Hackathons/docs/module-4-vla/chapter-2-voice-action"},"next":{"title":"Chapter 4: Autonomous Humanoid Architecture - The Complete System","permalink":"/Hackathons/docs/module-4-vla/chapter-4-autonomous-humanoid"}}');var t=i(4848),l=i(8453);const a={},r="Chapter 3: Cognitive Planning with LLMs - The Mind Behind the Robot",o={},c=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Introduction",id:"introduction",level:2},{value:"LLMs as Planners, Not Controllers",id:"llms-as-planners-not-controllers",level:2},{value:"The Planning Role",id:"the-planning-role",level:3},{value:"Why Not Direct Control?",id:"why-not-direct-control",level:3},{value:"The Cognitive Planner Architecture",id:"the-cognitive-planner-architecture",level:3},{value:"Translating Natural Language into Task Plans",id:"translating-natural-language-into-task-plans",level:2},{value:"Language Understanding and Goal Parsing",id:"language-understanding-and-goal-parsing",level:3},{value:"Task Structure Analysis",id:"task-structure-analysis",level:3},{value:"Plan Generation Process",id:"plan-generation-process",level:3},{value:"Decomposing Goals into ROS 2 Actions",id:"decomposing-goals-into-ros-2-actions",level:2},{value:"Action Primitives",id:"action-primitives",level:3},{value:"Hierarchical Decomposition",id:"hierarchical-decomposition",level:3},{value:"Example Decomposition",id:"example-decomposition",level:3},{value:"Failure Handling and Re-planning",id:"failure-handling-and-re-planning",level:2},{value:"Failure Detection",id:"failure-detection",level:3},{value:"Re-planning Strategies",id:"re-planning-strategies",level:3},{value:"Robust Planning",id:"robust-planning",level:3},{value:"Limits of LLM Reasoning in Physical Systems",id:"limits-of-llm-reasoning-in-physical-systems",level:2},{value:"Physical Reality Limitations",id:"physical-reality-limitations",level:3},{value:"Temporal and Causal Limitations",id:"temporal-and-causal-limitations",level:3},{value:"Embodied Reasoning Challenges",id:"embodied-reasoning-challenges",level:3},{value:"Cognitive Planning Best Practices",id:"cognitive-planning-best-practices",level:2},{value:"Validation and Verification",id:"validation-and-verification",level:3},{value:"Human-in-the-Loop",id:"human-in-the-loop",level:3},{value:"Incremental Planning",id:"incremental-planning",level:3},{value:"Key Takeaways",id:"key-takeaways",level:2},{value:"Further Reading/References",id:"further-readingreferences",level:2}];function d(n){const e={a:"a",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",strong:"strong",ul:"ul",...(0,l.R)(),...n.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(e.header,{children:(0,t.jsx)(e.h1,{id:"chapter-3-cognitive-planning-with-llms---the-mind-behind-the-robot",children:"Chapter 3: Cognitive Planning with LLMs - The Mind Behind the Robot"})}),"\n",(0,t.jsx)(e.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,t.jsx)(e.p,{children:"By the end of this chapter, you should be able to:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Explain how LLMs function as planners rather than controllers"}),"\n",(0,t.jsx)(e.li,{children:"Understand the process of translating natural language into task plans"}),"\n",(0,t.jsx)(e.li,{children:"Describe how goals decompose into ROS 2 actions"}),"\n",(0,t.jsx)(e.li,{children:"Identify failure handling and re-planning strategies"}),"\n",(0,t.jsx)(e.li,{children:"Recognize the limits of LLM reasoning in physical systems"}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"introduction",children:"Introduction"}),"\n",(0,t.jsx)(e.p,{children:"In Vision-Language-Action (VLA) systems, Large Language Models (LLMs) serve a crucial cognitive function as planners rather than direct controllers. This chapter explores cognitive planning, where LLMs process high-level goals and intentions, translating them into executable action sequences that respect physical constraints and safety requirements."}),"\n",(0,t.jsx)(e.h2,{id:"llms-as-planners-not-controllers",children:"LLMs as Planners, Not Controllers"}),"\n",(0,t.jsxs)(e.p,{children:["The fundamental principle in VLA systems is that ",(0,t.jsx)(e.strong,{children:"LLMs perform cognition and planning; ROS 2 performs execution. Never blur this line."})," This separation of concerns maintains system reliability while leveraging LLMs for high-level reasoning and planning."]}),"\n",(0,t.jsx)(e.h3,{id:"the-planning-role",children:"The Planning Role"}),"\n",(0,t.jsx)(e.p,{children:"As planners, LLMs in VLA systems perform several key functions:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Goal interpretation"}),": Understanding high-level user intentions expressed in natural language"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Task decomposition"}),": Breaking complex goals into sequences of executable actions"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Constraint awareness"}),": Considering physical, safety, and environmental constraints"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Resource allocation"}),": Planning efficient use of robot capabilities"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Failure anticipation"}),": Identifying potential failure points and planning alternatives"]}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"why-not-direct-control",children:"Why Not Direct Control?"}),"\n",(0,t.jsx)(e.p,{children:"Direct LLM-to-actuator control (treating LLMs as controllers) would be problematic for several reasons:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Reliability"}),": LLMs can generate inconsistent or unsafe commands"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Real-time requirements"}),": LLMs are not optimized for real-time control"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Safety"}),": Direct control bypasses safety validation and constraint checking"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Precision"}),": LLMs are not precise enough for low-level motor control"]}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"the-cognitive-planner-architecture",children:"The Cognitive Planner Architecture"}),"\n",(0,t.jsxs)(e.p,{children:["A ",(0,t.jsx)(e.strong,{children:"Cognitive Planner"})," is an LLM-based component that translates high-level goals into executable action sequences considering physical constraints. The cognitive planner operates at the intersection of language understanding and action execution, serving as a bridge between human intentions and robot behaviors."]}),"\n",(0,t.jsx)(e.h2,{id:"translating-natural-language-into-task-plans",children:"Translating Natural Language into Task Plans"}),"\n",(0,t.jsx)(e.p,{children:"The process of translating natural language commands into executable task plans involves several stages that transform high-level intentions into specific actions."}),"\n",(0,t.jsx)(e.h3,{id:"language-understanding-and-goal-parsing",children:"Language Understanding and Goal Parsing"}),"\n",(0,t.jsx)(e.p,{children:"The first stage involves parsing the natural language command to identify:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Intent"}),": What the user wants to accomplish"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Entities"}),": Objects, locations, and other entities involved"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Constraints"}),": Safety, timing, or other constraints on the task"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Context"}),": Environmental or situational context that affects the plan"]}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"task-structure-analysis",children:"Task Structure Analysis"}),"\n",(0,t.jsx)(e.p,{children:"Once the command is understood, the cognitive planner analyzes the task structure:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Sequential dependencies"}),": Actions that must occur in specific order"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Parallelizable components"}),": Actions that can occur simultaneously"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Resource requirements"}),": What robot capabilities are needed"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Success criteria"}),": How to determine when the task is complete"]}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"plan-generation-process",children:"Plan Generation Process"}),"\n",(0,t.jsx)(e.p,{children:"The cognitive planner generates a task plan by:"}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Identifying the goal state"}),": What the environment should look like after task completion"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Analyzing the current state"}),": Understanding the starting conditions"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Planning the transformation"}),": Determining the sequence of actions needed to move from current to goal state"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Validating constraints"}),": Ensuring the plan respects physical and safety constraints"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Optimizing the sequence"}),": Arranging actions for efficiency and reliability"]}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"decomposing-goals-into-ros-2-actions",children:"Decomposing Goals into ROS 2 Actions"}),"\n",(0,t.jsx)(e.p,{children:"The cognitive planner must decompose high-level goals into sequences of ROS 2 actions that can be executed by the robot. This decomposition process is crucial for bridging the gap between high-level intentions and low-level execution."}),"\n",(0,t.jsx)(e.h3,{id:"action-primitives",children:"Action Primitives"}),"\n",(0,t.jsx)(e.p,{children:"ROS 2 provides a set of action primitives that the cognitive planner can compose into complex behaviors:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Navigation actions"}),": Moving the robot to specific locations"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Manipulation actions"}),": Grasping, moving, or manipulating objects"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Perception actions"}),": Detecting, recognizing, or tracking objects"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Communication actions"}),": Providing feedback or requesting information"]}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"hierarchical-decomposition",children:"Hierarchical Decomposition"}),"\n",(0,t.jsx)(e.p,{children:"The decomposition process typically follows a hierarchical approach:"}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"High-level tasks"}),': Complex behaviors like "serve drinks at a party"']}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Mid-level capabilities"}),': Sequences like "fetch object and deliver it"']}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Low-level actions"}),": Individual ROS 2 action calls"]}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"example-decomposition",children:"Example Decomposition"}),"\n",(0,t.jsx)(e.p,{children:'Consider the command "Go to the kitchen and bring me a glass of water":'}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"High-level goal"}),": Bring user a glass of water"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Decomposed plan"}),":","\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsx)(e.li,{children:"Navigate to kitchen"}),"\n",(0,t.jsx)(e.li,{children:"Locate glass"}),"\n",(0,t.jsx)(e.li,{children:"Grasp glass"}),"\n",(0,t.jsx)(e.li,{children:"Navigate to water source"}),"\n",(0,t.jsx)(e.li,{children:"Fill glass with water"}),"\n",(0,t.jsx)(e.li,{children:"Navigate to user"}),"\n",(0,t.jsx)(e.li,{children:"Present glass to user"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(e.p,{children:"Each of these steps would be implemented as specific ROS 2 actions."}),"\n",(0,t.jsx)(e.h2,{id:"failure-handling-and-re-planning",children:"Failure Handling and Re-planning"}),"\n",(0,t.jsx)(e.p,{children:"Physical systems inevitably encounter failures, and cognitive planners must be designed to handle these gracefully. Failure handling and re-planning are essential capabilities for reliable VLA systems."}),"\n",(0,t.jsx)(e.h3,{id:"failure-detection",children:"Failure Detection"}),"\n",(0,t.jsx)(e.p,{children:"The cognitive planner must be able to detect various types of failures:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Action failures"}),": Individual actions that don't complete successfully"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Constraint violations"}),": Actions that violate safety or physical constraints"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Environmental changes"}),": Unexpected changes that invalidate the plan"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Goal impossibility"}),": Situations where the goal cannot be achieved"]}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"re-planning-strategies",children:"Re-planning Strategies"}),"\n",(0,t.jsx)(e.p,{children:"When failures occur, the cognitive planner can employ several re-planning strategies:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Local repair"}),": Modifying only the failed action or nearby actions"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Global re-plan"}),": Generating a completely new plan from the current state"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Goal relaxation"}),": Modifying the goal to make it achievable"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Alternative methods"}),": Using different approaches to achieve the same goal"]}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"robust-planning",children:"Robust Planning"}),"\n",(0,t.jsx)(e.p,{children:"To minimize failures, cognitive planners can incorporate:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Contingency planning"}),": Preparing alternative actions for likely failure modes"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Uncertainty modeling"}),": Accounting for uncertainty in action outcomes"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Risk assessment"}),": Evaluating the likelihood and consequences of different approaches"]}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"limits-of-llm-reasoning-in-physical-systems",children:"Limits of LLM Reasoning in Physical Systems"}),"\n",(0,t.jsx)(e.p,{children:"While LLMs are powerful tools for cognitive planning, they have significant limitations when applied to physical systems that must be understood and accommodated."}),"\n",(0,t.jsx)(e.h3,{id:"physical-reality-limitations",children:"Physical Reality Limitations"}),"\n",(0,t.jsx)(e.p,{children:"LLMs trained on text data may not fully understand physical reality:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Physics ignorance"}),": LLMs may generate plans that violate basic physics"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Scale confusion"}),": Difficulty understanding relative sizes and distances"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Material properties"}),": Limited understanding of material strengths, weights, fragility"]}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"temporal-and-causal-limitations",children:"Temporal and Causal Limitations"}),"\n",(0,t.jsx)(e.p,{children:"LLMs may struggle with temporal and causal reasoning:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Time estimation"}),": Difficulty estimating how long actions will take"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Causal chains"}),": Not fully understanding how actions affect the environment over time"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Concurrent effects"}),": Challenges with understanding simultaneous effects of multiple actions"]}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"embodied-reasoning-challenges",children:"Embodied Reasoning Challenges"}),"\n",(0,t.jsx)(e.p,{children:"LLMs lack embodied experience:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Perspective taking"}),": Difficulty understanding how the world looks from the robot's sensors"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Embodied knowledge"}),": Missing physical intuition that comes from embodied experience"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Action affordances"}),": Limited understanding of what actions are possible with specific robot configurations"]}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"cognitive-planning-best-practices",children:"Cognitive Planning Best Practices"}),"\n",(0,t.jsx)(e.p,{children:"Effective cognitive planning in VLA systems follows several best practices:"}),"\n",(0,t.jsx)(e.h3,{id:"validation-and-verification",children:"Validation and Verification"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Always validate plans against physical constraints before execution"}),"\n",(0,t.jsx)(e.li,{children:"Use simulation to test plans when possible"}),"\n",(0,t.jsx)(e.li,{children:"Implement safety checks at multiple levels"}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"human-in-the-loop",children:"Human-in-the-Loop"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Provide clear feedback about plan generation and execution"}),"\n",(0,t.jsx)(e.li,{children:"Allow humans to intervene when plans seem inappropriate"}),"\n",(0,t.jsx)(e.li,{children:"Use human feedback to improve planning over time"}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"incremental-planning",children:"Incremental Planning"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Plan in stages rather than attempting to plan complete sequences"}),"\n",(0,t.jsx)(e.li,{children:"Re-plan regularly based on new information"}),"\n",(0,t.jsx)(e.li,{children:"Use hierarchical planning to manage complexity"}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"key-takeaways",children:"Key Takeaways"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"LLMs function as cognitive planners, not direct controllers"}),"\n",(0,t.jsx)(e.li,{children:"The planning process transforms natural language into ROS 2 action sequences"}),"\n",(0,t.jsx)(e.li,{children:"Failure handling and re-planning are essential for robust operation"}),"\n",(0,t.jsx)(e.li,{children:"LLMs have limitations when reasoning about physical systems"}),"\n",(0,t.jsx)(e.li,{children:"Proper validation ensures safe and effective plan execution"}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"further-readingreferences",children:"Further Reading/References"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.a,{href:"/Hackathons/docs/module-4-vla/terminology",children:"Terminology Reference"})," - Key terms used in this module"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.a,{href:"./chapter-2-voice-action",children:"Chapter 2: Voice-to-Action Pipelines"})," - Background on intent mapping"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.a,{href:"/docs/modules/ros2-textbook/chapter-1-foundations",children:"Module 1: ROS 2 Foundations"})," - Background on ROS 2 actions"]}),"\n"]})]})}function h(n={}){const{wrapper:e}={...(0,l.R)(),...n.components};return e?(0,t.jsx)(e,{...n,children:(0,t.jsx)(d,{...n})}):d(n)}},8453(n,e,i){i.d(e,{R:()=>a,x:()=>r});var s=i(6540);const t={},l=s.createContext(t);function a(n){const e=s.useContext(l);return s.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function r(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(t):n.components||t:a(n.components),s.createElement(l.Provider,{value:e},n.children)}}}]);